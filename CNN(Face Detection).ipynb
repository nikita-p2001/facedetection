{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb17830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0877c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,MaxPooling2D,Flatten,Conv2D\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf933ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=r\"C:\\Users\\nikit\\OneDrive\\Desktop\\PDF\\IS\\Class Dataset IS3\\training\"\n",
    "test=r\"C:\\Users\\nikit\\OneDrive\\Desktop\\PDF\\IS\\Class Dataset IS3\\testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c245354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f665b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(224,224,3)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(15, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c3f8ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 111, 111, 32)      0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 186624)            0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 186624)            0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 15)                2799375   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,818,767\n",
      "Trainable params: 2,818,767\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a06ae513",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a00a5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e612959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c99a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c29d5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 315 images belonging to 15 classes.\n",
      "Found 135 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "        train,\n",
    "        target_size=(224,224),\n",
    "        batch_size=5,\n",
    "        class_mode='categorical')\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        test,\n",
    "        target_size=(225,224),\n",
    "        batch_size=5,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1daea1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Achal': 0,\n",
       " 'Anushka': 1,\n",
       " 'Fawzaan': 2,\n",
       " 'Lokesh': 3,\n",
       " 'Pranav': 4,\n",
       " 'Pushkar': 5,\n",
       " 'Samarth': 6,\n",
       " 'Sohail': 7,\n",
       " 'Sumit': 8,\n",
       " 'Sunny': 9,\n",
       " 'Susmit': 10,\n",
       " 'Umang': 11,\n",
       " 'Vaibhav': 12,\n",
       " 'Vivek_Patil': 13,\n",
       " 'Vivek_Pusti': 14}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c3e6951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of Face and its ID {0: 'Achal', 1: 'Anushka', 2: 'Fawzaan', 3: 'Lokesh', 4: 'Pranav', 5: 'Pushkar', 6: 'Samarth', 7: 'Sohail', 8: 'Sumit', 9: 'Sunny', 10: 'Susmit', 11: 'Umang', 12: 'Vaibhav', 13: 'Vivek_Patil', 14: 'Vivek_Pusti'}\n",
      "\n",
      " The Number of output neurons:  15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TrainClasses=training_set.class_indices\n",
    " \n",
    "# Storing the face and the numeric tag for future reference\n",
    "ResultMap={}\n",
    "for faceValue,faceName in zip(TrainClasses.values(),TrainClasses.keys()):\n",
    "    ResultMap[faceValue]=faceName\n",
    " \n",
    "# Saving the face map for future reference\n",
    "import pickle\n",
    "with open(\"ResultsMap.pkl\", 'wb') as fileWriteStream:\n",
    "    pickle.dump(ResultMap, fileWriteStream)\n",
    "\n",
    "print(\"Mapping of Face and its ID\",ResultMap)\n",
    "\n",
    "OutputNeurons=len(ResultMap)\n",
    "print('\\n The Number of output neurons: ', OutputNeurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a444e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "no_epochs = 30\n",
    "steps_per_epochs = no_epochs // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16254ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikit\\AppData\\Local\\Temp/ipykernel_11752/3588050712.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model1.fit_generator(training_set,steps_per_epoch=steps_per_epochs,epochs=no_epochs,validation_data=test_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6/6 [==============================] - 4s 764ms/step - loss: 0.2308 - accuracy: 0.3667 - val_loss: 0.6772 - val_accuracy: 0.3400\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 5s 830ms/step - loss: 0.1971 - accuracy: 0.4000 - val_loss: 0.6363 - val_accuracy: 0.3600\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 5s 799ms/step - loss: 0.2165 - accuracy: 0.4000 - val_loss: 0.6422 - val_accuracy: 0.3600\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 5s 850ms/step - loss: 0.1711 - accuracy: 0.5333 - val_loss: 0.6084 - val_accuracy: 0.4000\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 4s 726ms/step - loss: 0.1602 - accuracy: 0.5667 - val_loss: 0.5928 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 5s 853ms/step - loss: 0.1425 - accuracy: 0.6000 - val_loss: 0.5628 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 4s 694ms/step - loss: 0.1440 - accuracy: 0.6333 - val_loss: 0.5632 - val_accuracy: 0.5200\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 4s 767ms/step - loss: 0.1207 - accuracy: 0.7333 - val_loss: 0.4965 - val_accuracy: 0.5200\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 4s 659ms/step - loss: 0.1213 - accuracy: 0.7333 - val_loss: 0.4446 - val_accuracy: 0.5400\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 5s 803ms/step - loss: 0.0709 - accuracy: 0.9000 - val_loss: 0.4676 - val_accuracy: 0.5200\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 5s 862ms/step - loss: 0.0894 - accuracy: 0.8333 - val_loss: 0.3869 - val_accuracy: 0.6600\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 4s 798ms/step - loss: 0.0602 - accuracy: 0.9000 - val_loss: 0.2999 - val_accuracy: 0.7400\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 4s 725ms/step - loss: 0.0724 - accuracy: 0.8333 - val_loss: 0.2609 - val_accuracy: 0.8000\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 4s 763ms/step - loss: 0.0446 - accuracy: 0.9333 - val_loss: 0.2743 - val_accuracy: 0.7400\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 4s 739ms/step - loss: 0.0635 - accuracy: 0.9667 - val_loss: 0.2643 - val_accuracy: 0.8200\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 4s 676ms/step - loss: 0.0785 - accuracy: 0.8667 - val_loss: 0.2831 - val_accuracy: 0.6800\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 4s 709ms/step - loss: 0.0417 - accuracy: 0.9333 - val_loss: 0.2549 - val_accuracy: 0.8200\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 4s 706ms/step - loss: 0.0424 - accuracy: 0.9333 - val_loss: 0.2501 - val_accuracy: 0.9000\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 4s 773ms/step - loss: 0.0213 - accuracy: 0.9667 - val_loss: 0.2210 - val_accuracy: 0.8000\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 5s 844ms/step - loss: 0.0318 - accuracy: 0.9667 - val_loss: 0.1850 - val_accuracy: 0.8000\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 5s 957ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.8600\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 4s 695ms/step - loss: 0.0357 - accuracy: 0.9333 - val_loss: 0.1412 - val_accuracy: 0.9200\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 5s 983ms/step - loss: 0.0499 - accuracy: 0.9333 - val_loss: 0.1745 - val_accuracy: 0.8600\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 4s 695ms/step - loss: 0.0392 - accuracy: 0.9333 - val_loss: 0.1335 - val_accuracy: 0.9200\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 4s 721ms/step - loss: 0.0257 - accuracy: 0.9333 - val_loss: 0.1142 - val_accuracy: 0.9200\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 4s 710ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.8800\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 5s 813ms/step - loss: 0.0319 - accuracy: 0.9667 - val_loss: 0.0953 - val_accuracy: 0.9600\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 4s 768ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9200\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 4s 778ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9200\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 4s 661ms/step - loss: 0.0646 - accuracy: 0.9000 - val_loss: 0.1500 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x231022de880>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit_generator(training_set,steps_per_epoch=steps_per_epochs,epochs=no_epochs,validation_data=test_set,\n",
    "        validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03663112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3ac6a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7f9a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImagePath='C:\\\\Users\\\\nikit\\\\OneDrive\\\\Desktop\\\\PDF\\\\IS\\\\Class Dataset IS3\\\\testing\\\\Achal\\\\22.jpg'\n",
    "test_image=keras.utils.load_img(ImagePath,target_size=(224,224))\n",
    "test_image=keras.utils.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a53775ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image=np.expand_dims(test_image,axis=0)\n",
    " \n",
    "result=model1.predict(test_image,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94935d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is:  Achal\n"
     ]
    }
   ],
   "source": [
    "print('Prediction is: ',ResultMap[np.argmax(result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4794b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate_generator(test_set,verbose=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
